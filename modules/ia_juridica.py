"""
M√≥dulo de IA Jur√≠dica - Interface do Usu√°rio
Sistema Lopes &  Ribeiro
"""

import streamlit as st
import ai_gemini as ai
from datetime import datetime
import database as db
import pandas as pd
import PyPDF2
import docx
from docx import Document
import io
from io import BytesIO

def extract_text_from_pdf(file):
    """Extrai texto de um arquivo PDF"""
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Erro ao ler PDF: {e}"

def extract_text_from_docx(file):
    """Extrai texto de um arquivo DOCX"""
    try:
        doc = docx.Document(file)
        text = ""
        for para in doc.paragraphs:
            text += para.text + "\n"
        return text
    except Exception as e:
        return f"Erro ao ler DOCX: {e}"

def extract_text_from_txt(file):
    """Extrai texto de um arquivo TXT"""
    try:
        return file.getvalue().decode("utf-8")
    except Exception as e:
        return f"Erro ao ler TXT: {e}"

def gerar_docx(texto_ia):
    """Gera um arquivo DOCX com a resposta da IA"""
    doc = Document()
    doc.add_heading("Lopes & Ribeiro Advocacia - Parecer Jur√≠dico", 0)
    doc.add_paragraph(texto_ia)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def render():
    """Renderiza a interface do m√≥dulo de IA Jur√≠dica"""
    
    # Inicializar IA se ainda n√£o foi feito
    if 'ai_inicializada' not in st.session_state:
        with st.spinner("Inicializando IA..."):
            st.session_state.ai_inicializada = ai.inicializar_gemini()
    
    if not st.session_state.ai_inicializada:
        st.warning("‚ö†Ô∏è IA n√£o inicializada. Algumas funcionalidades podem estar indispon√≠veis. Verifique a configura√ß√£o da API Gemini.")
        # N√£o retorna mais, permite carregar o hist√≥rico

    
    st.title("ü§ñ Assistente Jur√≠dico Inteligente")
    st.caption("Powered by Google Gemini AI")
    
    # Tabs principais
    tab1, tab2, tab3, tab4 = st.tabs([
        "üí¨ Chat Assistente",
        "üìÑ An√°lise de Documentos",
        "üí° Sugest√µes Inteligentes",
        "üìö Hist√≥rico"
    ])
    
    # TAB 1: Chat Assistente
    with tab1:
        render_chat()
    
    # TAB 2: An√°lise de Documentos
    with tab2:
        render_analise_documentos()
    
    # TAB 3: Sugest√µes Inteligentes
    with tab3:
        render_sugestoes()
    
    # TAB 4: Hist√≥rico
    with tab4:
        render_historico()


def render_chat():
    """Renderiza interface de chat"""
    st.subheader("üí¨ Converse com o Assistente Jur√≠dico")
    
    if not st.session_state.get('ai_inicializada'):
        st.error("‚ùå IA Offline. Verifique configura√ß√µes.")
        return
    
    # A√ß√µes R√°pidas
    render_quick_actions()
    
    # Inicializar hist√≥rico de chat
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = [
            {"role": "assistant", "content": "Entendido. Estou pronto para atuar como Consultor S√™nior do Lopes & Ribeiro. Qual o pr√≥ximo caso?"}
        ]
    
    # Exibir hist√≥rico de mensagens
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    
    # Input de mensagem
    if prompt := st.chat_input("Digite sua pergunta jur√≠dica..."):
        # Adicionar mensagem do usu√°rio
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Gerar resposta da IA
        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                resposta = ai.chat_assistente(prompt)
                st.markdown(resposta)
                
                # Bot√£o de Download
                st.download_button(
                    label="üì• Baixar Parecer em Word (.docx)",
                    data=gerar_docx(resposta),
                    file_name="parecer_lopes_ribeiro_IA.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
        
        # Adicionar resposta ao hist√≥rico
        st.session_state.chat_history.append({"role": "assistant", "content": resposta})
        
        # Salvar no banco de dados
        try:
            with db.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO ai_historico (usuario, tipo, input, output, data_hora)
                    VALUES (?, ?, ?, ?, ?)
                """, (st.session_state.user, 'chat', prompt, resposta, datetime.now().isoformat()))
                conn.commit()
        except Exception as e:
            st.error(f"Erro ao salvar hist√≥rico: {e}")
    
    # Bot√£o para limpar chat
    if st.button("üóëÔ∏è Limpar Conversa"):
        st.session_state.chat_history = []
        st.rerun()


def render_analise_documentos():
    """Renderiza interface de an√°lise de documentos"""
    st.subheader("üìÑ An√°lise Inteligente de Documentos")
    
    if not st.session_state.get('ai_inicializada'):
        st.error("‚ùå IA Offline.")
        return
    
    st.info("üîç Cole o texto ou fa√ßa upload de um documento jur√≠dico para an√°lise autom√°tica")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        tipo_doc = st.selectbox(
            "Tipo de Documento",
            ["Peti√ß√£o Inicial", "Contrato", "Senten√ßa", "Ac√≥rd√£o", "Outro"]
        )
    
    # Upload de arquivo
    uploaded_file = st.file_uploader("Carregar arquivo (PDF, DOCX, TXT)", type=['pdf', 'docx', 'txt'])
    
    texto_extraido = ""
    if uploaded_file is not None:
        file_type = uploaded_file.name.split('.')[-1].lower()
        if file_type == 'pdf':
            texto_extraido = extract_text_from_pdf(uploaded_file)
        elif file_type == 'docx':
            texto_extraido = extract_text_from_docx(uploaded_file)
        elif file_type == 'txt':
            texto_extraido = extract_text_from_txt(uploaded_file)
            
        if texto_extraido.startswith("Erro"):
            st.error(texto_extraido)
            texto_extraido = ""
        elif not texto_extraido.strip():
            st.warning("‚ö†Ô∏è O texto extra√≠do est√° vazio ou ileg√≠vel. Se este documento for um PDF escaneado (imagem), a IA n√£o conseguir√° ler o conte√∫do.")
        else:
            st.success(f"Arquivo '{uploaded_file.name}' carregado com sucesso!")
    
    texto_documento = st.text_area(
        "Conte√∫do do documento:",
        value=texto_extraido if texto_extraido else "",
        height=300,
        placeholder="Cole aqui o conte√∫do do documento ou fa√ßa upload de um arquivo..."
    )
    
    if st.button("üîç Analisar Documento", type="primary"):
        if not texto_documento:
            st.warning("Por favor, forne√ßa um texto para an√°lise (cole ou fa√ßa upload)")
            return
        
        with st.spinner("Analisando documento..."):
            resultado = ai.analisar_documento(texto_documento, tipo_doc.lower())
            
            if 'erro' in resultado:
                st.error(f"‚ùå Erro na an√°lise: {resultado['erro']}")
            else:
                st.success("‚úÖ An√°lise conclu√≠da!")
                
                if resultado.get('from_cache'):
                    st.info("üì¶ Resultado obtido do cache (an√°lise anterior)")
                
                # Exibir an√°lise
                st.markdown("### üìä Resultado da An√°lise")
                st.markdown(resultado['analise'])
                
                # Bot√£o de Download
                st.download_button(
                    label="üì• Baixar Parecer em Word (.docx)",
                    data=gerar_docx(resultado['analise']),
                    file_name="analise_documento_lopes_ribeiro.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
                
                # Salvar no hist√≥rico
                try:
                    with db.get_connection() as conn:
                        cursor = conn.cursor()
                        cursor.execute("""
                            INSERT INTO ai_historico (usuario, tipo, input, output, data_hora)
                            VALUES (?, ?, ?, ?, ?)
                        """, (st.session_state.user, 'analise', texto_documento[:500], resultado['analise'], datetime.now().isoformat()))
                        conn.commit()
                except Exception as e:
                    st.error(f"Erro ao salvar an√°lise: {e}")


def render_sugestoes():
    """Renderiza sugest√µes inteligentes baseadas em processos"""
    st.subheader("üí° Sugest√µes Inteligentes")
    
    if not st.session_state.get('ai_inicializada'):
        st.error("‚ùå IA Offline.")
        return
    
    # Buscar processos ativos
    try:
        processos = db.sql_get('processos')
        
        if processos.empty:
            st.info("Nenhum processo encontrado para an√°lise.")
            return

        # Verificar se coluna status existe (compatibilidade)
        if 'status' not in processos.columns:
            # Tentar usar status_processo ou considerar todos ativos se n√£o tiver filtro
            if 'status_processo' in processos.columns:
                 processos_ativos = processos # Fallback, assume todos
            else:
                 processos_ativos = processos
        else:
            processos_ativos = processos[processos['status'] == 'Ativo']
        
        if processos_ativos.empty:
            st.info("Nenhum processo ativo encontrado")
            return
        
        selected_processo_id = st.selectbox(
            "Selecione um processo para obter sugest√µes:",
            options=processos_ativos['id'].tolist(),
            format_func=lambda x: f"Proc. {x} - {processos_ativos[processos_ativos['id']==x]['cliente_nome'].values[0]}"
        )
        
        if st.button("üí° Gerar Sugest√µes", type="primary"):
            # Buscar dados do processo
            processo_dados = processos_ativos[processos_ativos['id'] == selected_processo_id].iloc[0].to_dict()
            
            with st.spinner("Gerando sugest√µes..."):
                prompt = f"""
                Com base nos dados do processo abaixo, forne√ßa 5 sugest√µes pr√°ticas de pr√≥ximas a√ß√µes:
                
                N√∫mero (ID): {processo_dados.get('id')}
                A√ß√£o: {processo_dados.get('acao')}
                Status: {processo_dados.get('status')}
                Observa√ß√µes: {processo_dados.get('obs', 'Nenhuma')}
                
                Liste as sugest√µes de forma objetiva e pr√°tica.
                """
                
                resposta = ai.chat_assistente(prompt, contexto=processo_dados)
                
                st.markdown("### üìã Sugest√µes Geradas")
                st.markdown(resposta)
                
                # Bot√£o de Download
                st.download_button(
                    label="üì• Baixar Sugest√µes em Word (.docx)",
                    data=gerar_docx(resposta),
                    file_name="sugestoes_lopes_ribeiro.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
                
                # Salvar no hist√≥rico
                try:
                    with db.get_connection() as conn:
                        cursor = conn.cursor()
                        processo_id = processo_dados.get('id')
                        cursor.execute("""
                            INSERT INTO ai_historico (usuario, tipo, input, output, data_hora, processo_id)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (st.session_state.user, 'sugestao', str(processo_dados), resposta, datetime.now().isoformat(), processo_id))
                        conn.commit()
                except Exception as e:
                    st.error(f"Erro ao salvar sugest√µes: {e}")
    
    except Exception as e:
        st.error(f"Erro ao carregar processos: {e}")


def render_historico():
    """Renderiza hist√≥rico de intera√ß√µes com IA"""
    st.subheader("üìö Hist√≥rico de Intera√ß√µes")
    
    try:
        # Buscar hist√≥rico do banco
        with db.get_connection() as conn:
            historico = pd.read_sql_query("""
                SELECT * FROM ai_historico 
                WHERE usuario = ?
                ORDER BY data_hora DESC
                LIMIT 50
            """, conn, params=(st.session_state.user,))
        
        if historico.empty:
            st.info("Nenhuma intera√ß√£o registrada ainda")
            return
        
        # Filtros
        col1, col2 = st.columns(2)
        with col1:
            filtro_tipo = st.multiselect(
                "Filtrar por tipo:",
                options=['chat', 'analise', 'sugestao'],
                default=['chat', 'analise', 'sugestao']
            )
        
        # Aplicar filtro
        historico_filtrado = historico[historico['tipo'].isin(filtro_tipo)]
        
        # Exibir hist√≥rico
        for idx, row in historico_filtrado.iterrows():
            with st.expander(f"ü§ñ {row['tipo'].upper()} - {row['data_hora'][:16]}"):
                st.markdown(f"**Entrada:**\n{row['input'][:200]}...")
                st.markdown(f"**Resposta:**\n{row['output'][:300]}...")
                
                if row['processo_id']:
                    st.caption(f"Vinculado ao processo ID: {row['processo_id']}")
    
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")

# --- FUN√á√ïES DE CONTEXTO ---

def get_contexto_financeiro():
    """Coleta dados financeiros para an√°lise da IA"""
    try:
        df = db.sql_get("financeiro")
        if df.empty: return "Sem dados financeiros."
        
        # Resumo
        total_entrada = df[df['tipo']=='Entrada']['valor'].sum()
        total_saida = df[df['tipo']=='Sa√≠da']['valor'].sum()
        saldo = total_entrada - total_saida
        
        # Inadimpl√™ncia
        inadimplentes = df[(df['tipo']=='Entrada') & (df['status_pagamento']=='Pendente') & (df['vencimento'] < datetime.now().strftime('%Y-%m-%d'))]
        total_inad = inadimplentes['valor'].sum()
        
        return {
            "resumo_geral": {
                "total_entradas": total_entrada,
                "total_saidas": total_saida,
                "saldo": saldo,
                "inadimplencia_total": total_inad
            },
            "top_inadimplentes": inadimplentes[['descricao', 'valor', 'vencimento']].head(5).to_dict('records')
        }
    except Exception as e:
        return f"Erro ao buscar financeiro: {e}"

def get_contexto_processos():
    """Coleta processos parados h√° muito tempo"""
    try:
        df = db.sql_get("processos")
        if df.empty: return "Sem processos."
        
        # Filtrar ativos
        ativos = df[df['status'] == 'Ativo']
        # Simula√ß√£o de "parados": sem andamento recente (idealmente cruzaria com tabela andamentos, mas vamos simplificar)
        # Vamos pegar os 5 mais antigos por data de distribui√ß√£o
        antigos = ativos.sort_values('data_distribuicao').head(5)
        
        return {
            "total_ativos": len(ativos),
            "processos_antigos_atencao": antigos[['numero', 'cliente_nome', 'acao', 'data_distribuicao']].to_dict('records')
        }
    except Exception as e:
        return f"Erro ao buscar processos: {e}"

def get_contexto_propostas():
    """Coleta dados do funil de vendas"""
    try:
        df = db.sql_get("clientes")
        if df.empty: return "Sem clientes."
        
        em_negociacao = df[df['status_cliente'] == 'EM NEGOCIA√á√ÉO']
        total_potencial = em_negociacao['proposta_valor'].sum()
        
        return {
            "clientes_em_negociacao": len(em_negociacao),
            "valor_total_pipeline": total_potencial,
            "lista_propostas": em_negociacao[['nome', 'proposta_valor', 'status_proposta']].to_dict('records')
        }
    except Exception as e:
        return f"Erro ao buscar propostas: {e}"

def render_quick_actions():
    """Renderiza bot√µes de a√ß√£o r√°pida"""
    st.markdown("##### ‚ö° A√ß√µes R√°pidas")
    c1, c2, c3 = st.columns(3)
    
    prompt_auto = None
    contexto_auto = None
    
    if c1.button("üí∞ Analisar Financeiro", use_container_width=True):
        contexto_auto = get_contexto_financeiro()
        prompt_auto = "Analise a sa√∫de financeira do escrit√≥rio com base nestes dados. Identifique pontos de aten√ß√£o, inadimpl√™ncia e sugira melhorias."
        
    if c2.button("‚öñÔ∏è Processos Parados", use_container_width=True):
        contexto_auto = get_contexto_processos()
        prompt_auto = "Analise estes processos que est√£o antigos ou parados. Sugira despachos ou medidas para dar andamento."
        
    if c3.button("ü§ù Analisar Propostas", use_container_width=True):
        contexto_auto = get_contexto_propostas()
        prompt_auto = "Analise o funil de vendas e as propostas em aberto. Sugira estrat√©gias para fechar esses contratos."
        
    # Se clicou em algum bot√£o, processa automaticamente
    if prompt_auto:
        # Adicionar ao hist√≥rico visual
        st.session_state.chat_history.append({"role": "user", "content": f"üîÑ [A√ß√£o R√°pida] {prompt_auto}"})
        
        with st.spinner("ü§ñ Analisando dados do sistema..."):
            resposta = ai.chat_assistente(prompt_auto, contexto=contexto_auto)
            st.session_state.chat_history.append({"role": "assistant", "content": resposta})
            st.rerun()
